{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting tweets based on top words from Conservative and Liberal subredits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_tweets import get_tweets\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "searching tweets with id  < 1297657548791660545\n",
      "searching tweets with id  < 1297657541631963136\n",
      "searching tweets with id  < 1297657534283575296\n",
      "searching tweets with id  < 1297657526675214336\n",
      "searching tweets with id  < 1297657520270405632\n",
      "searching tweets with id  < 1297657512242495488\n",
      "searching tweets with id  < 1297657504973955072\n",
      "searching tweets with id  < 1297657497021546501\n",
      "searching tweets with id  < 1297657490033827842\n",
      "Got Trump tweets\n",
      "200\n",
      "searching tweets with id  < 1297657551442587655\n",
      "searching tweets with id  < 1297657519788228608\n",
      "searching tweets with id  < 1297657485793386496\n",
      "searching tweets with id  < 1297657450087297027\n",
      "searching tweets with id  < 1297657417975693315\n",
      "searching tweets with id  < 1297657380897992711\n",
      "searching tweets with id  < 1297657347620446209\n",
      "searching tweets with id  < 1297657314179198976\n",
      "searching tweets with id  < 1297657290011455489\n",
      "Got Biden tweets\n",
      "200\n",
      "searching tweets with id  < 1297657467820793856\n",
      "searching tweets with id  < 1297657326959243264\n",
      "searching tweets with id  < 1297657198470823936\n",
      "searching tweets with id  < 1297657061313052673\n",
      "searching tweets with id  < 1297656918215991297\n",
      "searching tweets with id  < 1297656788934959106\n",
      "searching tweets with id  < 1297656652053741569\n",
      "searching tweets with id  < 1297656525729738755\n",
      "searching tweets with id  < 1297656396700295169\n",
      "Got Black Lives Matters tweets\n",
      "200\n",
      "searching tweets with id  < 1297657527190958081\n",
      "searching tweets with id  < 1297657371846746114\n",
      "searching tweets with id  < 1297657233510150145\n",
      "searching tweets with id  < 1297657081831362560\n",
      "searching tweets with id  < 1297656952248508419\n",
      "searching tweets with id  < 1297656813614247938\n",
      "searching tweets with id  < 1297656674090614786\n",
      "searching tweets with id  < 1297656543429767168\n",
      "searching tweets with id  < 1297656428555993088\n",
      "Got Antifa tweets\n",
      "200\n",
      "searching tweets with id  < 1297657554710007812\n",
      "searching tweets with id  < 1297657412485181440\n",
      "searching tweets with id  < 1297657261532180480\n",
      "searching tweets with id  < 1297657105835597824\n",
      "searching tweets with id  < 1297656961735917568\n",
      "searching tweets with id  < 1297656809029873666\n",
      "searching tweets with id  < 1297656666037432320\n",
      "searching tweets with id  < 1297656507799146497\n",
      "searching tweets with id  < 1297656330325356544\n",
      "Got Portland tweets\n"
     ]
    }
   ],
   "source": [
    "# Tweets searching for top words from Conservative subreddit from past month\n",
    "trump = get_tweets(\"trump\", 1000)\n",
    "print(\"Got Trump tweets\")\n",
    "\n",
    "biden = get_tweets(\"biden\", 1000)\n",
    "print(\"Got Biden tweets\")\n",
    "\n",
    "blm = get_tweets('BLM', 1000)\n",
    "print(\"Got Black Lives Matters tweets\")\n",
    "\n",
    "antifa = get_tweets('antifa', 1000)\n",
    "print(\"Got Antifa tweets\")\n",
    "\n",
    "portland = get_tweets(\"portland\", 1000)\n",
    "print(\"Got Portland tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_tweets = [trump, biden, blm, antifa, portland]\n",
    "conservative = pd.concat(cons_tweets, ignore_index=True, sort = True)\n",
    "conservative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top words from all of these subreddits are not mutually exclusive. Therefore, we will only pull those tweets that appear in more than one subreddit once and focus on more unique top words as other choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets searching for top words from Liberal subreddit from past year since there is significantly less activity on this one\n",
    "coronavirus = get_tweets('coronavirus', 1000)\n",
    "print(\"Got Coronavirus tweets\")\n",
    "\n",
    "democrats = get_tweets('democrats', 1000)\n",
    "print('Got Democrat tweets')\n",
    "\n",
    "# republican = get_tweets('republican', 1000)\n",
    "# print(\"Got Republican tweets\")\n",
    "\n",
    "ukraine = get_tweets('ukraine', 1000)\n",
    "print(\"Got Ukraine tweets\")\n",
    "\n",
    "police = get_tweets('police', 1000)\n",
    "print(\"Got police tweets\")\n",
    "\n",
    "protest = get_tweets('protest', 1000)\n",
    "print(\"Got protest tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_tweets = [coronavirus, democrats, ukraine, police, protest]\n",
    "liberal = pd.concat(lib_tweets, ignore_index=True, sort = True)\n",
    "liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative.to_csv(\"data/conservative.csv\")\n",
    "liberal.to_csv('data/liberal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 91654561,\n",
       " 'id_str': '91654561',\n",
       " 'name': 'Ken Lukasiewicz',\n",
       " 'screen_name': 'kenluke',\n",
       " 'location': 'Connecticut',\n",
       " 'description': '',\n",
       " 'url': None,\n",
       " 'entities': {'description': {'urls': []}},\n",
       " 'protected': False,\n",
       " 'followers_count': 636,\n",
       " 'friends_count': 32,\n",
       " 'listed_count': 16,\n",
       " 'created_at': 'Sat Nov 21 21:11:50 +0000 2009',\n",
       " 'favourites_count': 89653,\n",
       " 'utc_offset': None,\n",
       " 'time_zone': None,\n",
       " 'geo_enabled': True,\n",
       " 'verified': False,\n",
       " 'statuses_count': 100997,\n",
       " 'lang': None,\n",
       " 'contributors_enabled': False,\n",
       " 'is_translator': False,\n",
       " 'is_translation_enabled': False,\n",
       " 'profile_background_color': 'ACDED6',\n",
       " 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme18/bg.gif',\n",
       " 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme18/bg.gif',\n",
       " 'profile_background_tile': False,\n",
       " 'profile_image_url': 'http://pbs.twimg.com/profile_images/537600749/74_reunion_closeup_normal.jpg',\n",
       " 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/537600749/74_reunion_closeup_normal.jpg',\n",
       " 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/91654561/1373729604',\n",
       " 'profile_link_color': '038543',\n",
       " 'profile_sidebar_border_color': 'EEEEEE',\n",
       " 'profile_sidebar_fill_color': 'F6F6F6',\n",
       " 'profile_text_color': '333333',\n",
       " 'profile_use_background_image': True,\n",
       " 'has_extended_profile': False,\n",
       " 'default_profile': False,\n",
       " 'default_profile_image': False,\n",
       " 'following': None,\n",
       " 'follow_request_sent': None,\n",
       " 'notifications': None,\n",
       " 'translator_type': 'none'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      en\n",
       "1      en\n",
       "2      en\n",
       "3      en\n",
       "4      en\n",
       "       ..\n",
       "995    en\n",
       "996    en\n",
       "997    en\n",
       "998    en\n",
       "999    en\n",
       "Name: lang, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
